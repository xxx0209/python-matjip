# app/services/hf_service.py

from typing import List, Dict, Optional

HF_AVAILABLE = False
generator = None

try:
    from transformers import pipeline

    # ğŸ”¥ ì„œë²„ ì‹œì‘ ì‹œ 1ë²ˆë§Œ ë¡œë“œë¨
    generator = pipeline(
        "text-generation",
        model="distilgpt2",
        device=-1  # CPU ì‚¬ìš© (GPU ìˆìœ¼ë©´ 0)
    )
    HF_AVAILABLE = True
    print("âœ… HuggingFace ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    print("âŒ HuggingFace ë¡œë“œ ì‹¤íŒ¨:", e)
    HF_AVAILABLE = False


def generate_hf_comment(question: str, places: List[Dict]) -> Optional[str]:
    """
    HuggingFace ê¸°ë°˜ ì¶”ì²œ ë©˜íŠ¸ ìƒì„±
    ì‹¤íŒ¨í•˜ë©´ None ë°˜í™˜ â†’ ìƒìœ„ì—ì„œ fallback ì²˜ë¦¬
    """

    if not HF_AVAILABLE or not places:
        return None

    try:
        place_names = ", ".join([p["name"] for p in places[:5]])

        prompt = (
            f"ì‚¬ìš©ì ì§ˆë¬¸: {question}\n"
            f"ì¶”ì²œí•  ì¥ì†Œ: {place_names}\n"
            "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë¬¸ì¥ ì¶”ì²œí•´ì¤˜:"
        )

        result = generator(
            prompt,
            max_length=60,
            do_sample=True,
            temperature=0.7,
            num_return_sequences=1
        )

        text = result[0]["generated_text"]

        # ğŸ”¥ í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì œê±° (distilgpt2 íŠ¹ì„± ëŒ€ì‘)
        if "ì¶”ì²œí•´ì¤˜:" in text:
            text = text.split("ì¶”ì²œí•´ì¤˜:")[-1].strip()

        return text

    except Exception as e:
        print("HF ìƒì„± ì‹¤íŒ¨:", e)
        return None
